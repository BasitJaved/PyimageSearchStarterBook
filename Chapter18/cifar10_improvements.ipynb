{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing, scaling reshaping and vectorizing the data set\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "#scaling data\n",
    "trainX = trainX.astype('float')/255.0\n",
    "testX = testX.astype('float')/255.0\n",
    "\n",
    "\n",
    "#vectorizing the labels\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the label names\n",
    "labelNames = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', \n",
    "             'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "chanDim= -1\n",
    "def model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    #first layer of Conv2D\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #second layer of Conv2D\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #FC layet\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\b84145862\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,171,434\n",
      "Trainable params: 2,169,898\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initializing the optimizer and model\n",
    "opt = SGD(lr = 0.01, decay = 0.01/40, momentum = 0.9, nesterov = True)\n",
    "model = model()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.9958 - acc: 0.6531\n",
      "Epoch 00001: val_loss improved from inf to 0.85552, saving model to weights\\weights -001 - 0.8555.hdf5\n",
      "50000/50000 [==============================] - 11s 215us/sample - loss: 0.9958 - acc: 0.6531 - val_loss: 0.8555 - val_acc: 0.6993\n",
      "Epoch 2/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.8885 - acc: 0.6891\n",
      "Epoch 00002: val_loss improved from 0.85552 to 0.79944, saving model to weights\\weights -002 - 0.7994.hdf5\n",
      "50000/50000 [==============================] - 11s 215us/sample - loss: 0.8882 - acc: 0.6892 - val_loss: 0.7994 - val_acc: 0.7167\n",
      "Epoch 3/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.8048 - acc: 0.7180\n",
      "Epoch 00003: val_loss did not improve from 0.79944\n",
      "50000/50000 [==============================] - 11s 228us/sample - loss: 0.8046 - acc: 0.7181 - val_loss: 0.8032 - val_acc: 0.7177\n",
      "Epoch 4/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.7461 - acc: 0.7376\n",
      "Epoch 00004: val_loss improved from 0.79944 to 0.67357, saving model to weights\\weights -004 - 0.6736.hdf5\n",
      "50000/50000 [==============================] - 12s 236us/sample - loss: 0.7461 - acc: 0.7376 - val_loss: 0.6736 - val_acc: 0.7689\n",
      "Epoch 5/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.6992 - acc: 0.7536\n",
      "Epoch 00005: val_loss did not improve from 0.67357\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 0.6988 - acc: 0.7538 - val_loss: 0.6839 - val_acc: 0.7646\n",
      "Epoch 6/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6613 - acc: 0.7670\n",
      "Epoch 00006: val_loss did not improve from 0.67357\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 0.6613 - acc: 0.7670 - val_loss: 0.6977 - val_acc: 0.7632\n",
      "Epoch 7/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.6277 - acc: 0.7782\n",
      "Epoch 00007: val_loss did not improve from 0.67357\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 0.6281 - acc: 0.7781 - val_loss: 0.6820 - val_acc: 0.7669\n",
      "Epoch 8/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.7910\n",
      "Epoch 00008: val_loss improved from 0.67357 to 0.61632, saving model to weights\\weights -008 - 0.6163.hdf5\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 0.5950 - acc: 0.7909 - val_loss: 0.6163 - val_acc: 0.7853\n",
      "Epoch 9/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7985\n",
      "Epoch 00009: val_loss improved from 0.61632 to 0.61438, saving model to weights\\weights -009 - 0.6144.hdf5\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 0.5702 - acc: 0.7985 - val_loss: 0.6144 - val_acc: 0.7896\n",
      "Epoch 10/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.8062\n",
      "Epoch 00010: val_loss improved from 0.61438 to 0.61022, saving model to weights\\weights -010 - 0.6102.hdf5\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 0.5462 - acc: 0.8062 - val_loss: 0.6102 - val_acc: 0.7883\n",
      "Epoch 11/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.8151\n",
      "Epoch 00011: val_loss improved from 0.61022 to 0.59780, saving model to weights\\weights -011 - 0.5978.hdf5\n",
      "50000/50000 [==============================] - 11s 226us/sample - loss: 0.5246 - acc: 0.8151 - val_loss: 0.5978 - val_acc: 0.7945\n",
      "Epoch 12/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.8215\n",
      "Epoch 00012: val_loss improved from 0.59780 to 0.57060, saving model to weights\\weights -012 - 0.5706.hdf5\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 0.5005 - acc: 0.8215 - val_loss: 0.5706 - val_acc: 0.8018\n",
      "Epoch 13/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8302- \n",
      "Epoch 00013: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 0.4835 - acc: 0.8301 - val_loss: 0.6007 - val_acc: 0.7923\n",
      "Epoch 14/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8362\n",
      "Epoch 00014: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 0.4657 - acc: 0.8363 - val_loss: 0.6052 - val_acc: 0.7985\n",
      "Epoch 15/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8400\n",
      "Epoch 00015: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 0.4525 - acc: 0.8400 - val_loss: 0.5799 - val_acc: 0.8029\n",
      "Epoch 16/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4373 - acc: 0.8444\n",
      "Epoch 00016: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 0.4374 - acc: 0.8443 - val_loss: 0.5894 - val_acc: 0.8010\n",
      "Epoch 17/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8476\n",
      "Epoch 00017: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 0.4264 - acc: 0.8475 - val_loss: 0.5925 - val_acc: 0.8030\n",
      "Epoch 18/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8534\n",
      "Epoch 00018: val_loss did not improve from 0.57060\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 0.4090 - acc: 0.8534 - val_loss: 0.5707 - val_acc: 0.8047\n",
      "Epoch 19/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8578\n",
      "Epoch 00019: val_loss improved from 0.57060 to 0.56149, saving model to weights\\weights -019 - 0.5615.hdf5\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 0.4000 - acc: 0.8577 - val_loss: 0.5615 - val_acc: 0.8117\n",
      "Epoch 20/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3894 - acc: 0.8609\n",
      "Epoch 00020: val_loss did not improve from 0.56149\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 0.3896 - acc: 0.8608 - val_loss: 0.5729 - val_acc: 0.8082\n",
      "Epoch 21/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8678\n",
      "Epoch 00021: val_loss improved from 0.56149 to 0.54848, saving model to weights\\weights -021 - 0.5485.hdf5\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 0.3725 - acc: 0.8679 - val_loss: 0.5485 - val_acc: 0.8152\n",
      "Epoch 22/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3645 - acc: 0.8695\n",
      "Epoch 00022: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 0.3648 - acc: 0.8694 - val_loss: 0.5510 - val_acc: 0.8145\n",
      "Epoch 23/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8741\n",
      "Epoch 00023: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 0.3547 - acc: 0.8741 - val_loss: 0.5632 - val_acc: 0.8108\n",
      "Epoch 24/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.3442 - acc: 0.8776\n",
      "Epoch 00024: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 0.3442 - acc: 0.8777 - val_loss: 0.5544 - val_acc: 0.8147\n",
      "Epoch 25/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8797\n",
      "Epoch 00025: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.3378 - acc: 0.8798 - val_loss: 0.5600 - val_acc: 0.8165\n",
      "Epoch 26/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3299 - acc: 0.8821\n",
      "Epoch 00026: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 0.3303 - acc: 0.8819 - val_loss: 0.5556 - val_acc: 0.8167\n",
      "Epoch 27/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.8836\n",
      "Epoch 00027: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.3233 - acc: 0.8836 - val_loss: 0.5597 - val_acc: 0.8190\n",
      "Epoch 28/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.8874\n",
      "Epoch 00028: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 0.3178 - acc: 0.8874 - val_loss: 0.5666 - val_acc: 0.8137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3131 - acc: 0.8864\n",
      "Epoch 00029: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 0.3132 - acc: 0.8864 - val_loss: 0.5611 - val_acc: 0.8175\n",
      "Epoch 30/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.8917\n",
      "Epoch 00030: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 217us/sample - loss: 0.3029 - acc: 0.8917 - val_loss: 0.5541 - val_acc: 0.8169\n",
      "Epoch 31/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.8944\n",
      "Epoch 00031: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.2958 - acc: 0.8944 - val_loss: 0.5491 - val_acc: 0.8193\n",
      "Epoch 32/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8982\n",
      "Epoch 00032: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.2897 - acc: 0.8982 - val_loss: 0.5536 - val_acc: 0.8223\n",
      "Epoch 33/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.8985\n",
      "Epoch 00033: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.2851 - acc: 0.8985 - val_loss: 0.5815 - val_acc: 0.8183\n",
      "Epoch 34/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.8999\n",
      "Epoch 00034: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 0.2791 - acc: 0.8999 - val_loss: 0.5558 - val_acc: 0.8184\n",
      "Epoch 35/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.2736 - acc: 0.9012- ETA: 0s - loss: 0.2728 - acc:\n",
      "Epoch 00035: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 0.2736 - acc: 0.9012 - val_loss: 0.5611 - val_acc: 0.8177\n",
      "Epoch 36/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.9039\n",
      "Epoch 00036: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.2702 - acc: 0.9039 - val_loss: 0.5535 - val_acc: 0.8192\n",
      "Epoch 37/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9061\n",
      "Epoch 00037: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 0.2656 - acc: 0.9060 - val_loss: 0.5687 - val_acc: 0.8212\n",
      "Epoch 38/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9065\n",
      "Epoch 00038: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 0.2598 - acc: 0.9065 - val_loss: 0.5623 - val_acc: 0.8184\n",
      "Epoch 39/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2570 - acc: 0.9082\n",
      "Epoch 00039: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 0.2569 - acc: 0.9082 - val_loss: 0.5627 - val_acc: 0.8222\n",
      "Epoch 40/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2520 - acc: 0.9093\n",
      "Epoch 00040: val_loss did not improve from 0.54848\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.2524 - acc: 0.9093 - val_loss: 0.5614 - val_acc: 0.8240\n"
     ]
    }
   ],
   "source": [
    "fname = os.path.sep.join(['weights', \n",
    "                          'weights -{epoch:03d} - {val_loss:.4f}.hdf5'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(fname, monitor = 'val_loss', \n",
    "                             mode = 'min', save_best_only = True, \n",
    "                             verbose = 1)\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data = (testX, testY), \n",
    "              batch_size = 64, epochs = 40, callbacks = callbacks, \n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
