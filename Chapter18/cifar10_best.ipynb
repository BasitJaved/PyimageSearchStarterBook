{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing, scaling reshaping and vectorizing the data set\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "\n",
    "#scaling data\n",
    "trainX = trainX.astype('float')/255.0\n",
    "testX = testX.astype('float')/255.0\n",
    "\n",
    "\n",
    "#vectorizing the labels\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the label names\n",
    "labelNames = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', \n",
    "             'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "chanDim= -1\n",
    "def model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    #first layer of Conv2D\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #second layer of Conv2D\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #FC layet\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\b84145862\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,171,434\n",
      "Trainable params: 2,169,898\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initializing the optimizer and model\n",
    "opt = SGD(lr = 0.01, decay = 0.01/40, momentum = 0.9, nesterov = True)\n",
    "model = model()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 1.6350 - acc: 0.4524- ETA: 1s - loss: 1.6905 - a - ETA: 1s - loss: 1.668\n",
      "Epoch 00001: val_loss improved from inf to 1.36887, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 1.6329 - acc: 0.4530 - val_loss: 1.3689 - val_acc: 0.5316\n",
      "Epoch 2/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 1.1733 - acc: 0.5896\n",
      "Epoch 00002: val_loss improved from 1.36887 to 0.96748, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 217us/sample - loss: 1.1727 - acc: 0.5900 - val_loss: 0.9675 - val_acc: 0.6585\n",
      "Epoch 3/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.9745 - acc: 0.6551\n",
      "Epoch 00003: val_loss improved from 0.96748 to 0.84864, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 0.9748 - acc: 0.6552 - val_loss: 0.8486 - val_acc: 0.7038\n",
      "Epoch 4/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.8700 - acc: 0.6940\n",
      "Epoch 00004: val_loss improved from 0.84864 to 0.78740, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.8700 - acc: 0.6941 - val_loss: 0.7874 - val_acc: 0.7218\n",
      "Epoch 5/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.7929 - acc: 0.7223\n",
      "Epoch 00005: val_loss improved from 0.78740 to 0.74869, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.7928 - acc: 0.7223 - val_loss: 0.7487 - val_acc: 0.7407\n",
      "Epoch 6/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.7294 - acc: 0.7399\n",
      "Epoch 00006: val_loss improved from 0.74869 to 0.74457, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.7296 - acc: 0.7399 - val_loss: 0.7446 - val_acc: 0.7431\n",
      "Epoch 7/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.6854 - acc: 0.7571\n",
      "Epoch 00007: val_loss improved from 0.74457 to 0.71726, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.6854 - acc: 0.7571 - val_loss: 0.7173 - val_acc: 0.7555\n",
      "Epoch 8/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.6492 - acc: 0.7705\n",
      "Epoch 00008: val_loss improved from 0.71726 to 0.65069, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.6493 - acc: 0.7705 - val_loss: 0.6507 - val_acc: 0.7729\n",
      "Epoch 9/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.6200 - acc: 0.7815\n",
      "Epoch 00009: val_loss did not improve from 0.65069\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.6196 - acc: 0.7816 - val_loss: 0.6593 - val_acc: 0.7731\n",
      "Epoch 10/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.7935\n",
      "Epoch 00010: val_loss improved from 0.65069 to 0.62663, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 0.5805 - acc: 0.7934 - val_loss: 0.6266 - val_acc: 0.7844\n",
      "Epoch 11/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8010\n",
      "Epoch 00011: val_loss improved from 0.62663 to 0.61249, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 12s 230us/sample - loss: 0.5612 - acc: 0.8012 - val_loss: 0.6125 - val_acc: 0.7938\n",
      "Epoch 12/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.5370 - acc: 0.8089\n",
      "Epoch 00012: val_loss did not improve from 0.61249\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 0.5371 - acc: 0.8088 - val_loss: 0.6399 - val_acc: 0.7841\n",
      "Epoch 13/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.5152 - acc: 0.8178\n",
      "Epoch 00013: val_loss improved from 0.61249 to 0.60370, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 0.5153 - acc: 0.8178 - val_loss: 0.6037 - val_acc: 0.7915\n",
      "Epoch 14/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.8253\n",
      "Epoch 00014: val_loss improved from 0.60370 to 0.59123, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 0.4972 - acc: 0.8253 - val_loss: 0.5912 - val_acc: 0.8057\n",
      "Epoch 15/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8325\n",
      "Epoch 00015: val_loss improved from 0.59123 to 0.56888, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.4725 - acc: 0.8325 - val_loss: 0.5689 - val_acc: 0.8093\n",
      "Epoch 16/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4552 - acc: 0.8395\n",
      "Epoch 00016: val_loss did not improve from 0.56888\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.4552 - acc: 0.8395 - val_loss: 0.5794 - val_acc: 0.8064\n",
      "Epoch 17/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8430- ETA: 0s - loss: 0.4427 - acc: 0.84\n",
      "Epoch 00017: val_loss did not improve from 0.56888\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.4433 - acc: 0.8430 - val_loss: 0.5707 - val_acc: 0.8098\n",
      "Epoch 18/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4277 - acc: 0.8472\n",
      "Epoch 00018: val_loss improved from 0.56888 to 0.55723, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.4274 - acc: 0.8473 - val_loss: 0.5572 - val_acc: 0.8108\n",
      "Epoch 19/40\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8507\n",
      "Epoch 00019: val_loss did not improve from 0.55723\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 0.4183 - acc: 0.8509 - val_loss: 0.5771 - val_acc: 0.8113\n",
      "Epoch 20/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.8578\n",
      "Epoch 00020: val_loss did not improve from 0.55723\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 0.4001 - acc: 0.8576 - val_loss: 0.5619 - val_acc: 0.8136\n",
      "Epoch 21/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3895 - acc: 0.8613\n",
      "Epoch 00021: val_loss did not improve from 0.55723\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.3899 - acc: 0.8611 - val_loss: 0.5675 - val_acc: 0.8165\n",
      "Epoch 22/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8645\n",
      "Epoch 00022: val_loss did not improve from 0.55723\n",
      "50000/50000 [==============================] - 11s 219us/sample - loss: 0.3805 - acc: 0.8647 - val_loss: 0.5579 - val_acc: 0.8181\n",
      "Epoch 23/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.8666\n",
      "Epoch 00023: val_loss improved from 0.55723 to 0.55435, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 12s 234us/sample - loss: 0.3740 - acc: 0.8666 - val_loss: 0.5544 - val_acc: 0.8178\n",
      "Epoch 24/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3606 - acc: 0.8711- ETA: 0s - loss: 0.3593 - acc: - ETA: 0s - loss: 0.3601 - acc: \n",
      "Epoch 00024: val_loss did not improve from 0.55435\n",
      "50000/50000 [==============================] - 12s 242us/sample - loss: 0.3602 - acc: 0.8713 - val_loss: 0.5686 - val_acc: 0.8153\n",
      "Epoch 25/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3539 - acc: 0.8729- ETA: 0s - loss: 0.3543 -\n",
      "Epoch 00025: val_loss improved from 0.55435 to 0.54084, saving model to weights/cifar10_best_weights.hdf5\n",
      "50000/50000 [==============================] - 13s 261us/sample - loss: 0.3546 - acc: 0.8728 - val_loss: 0.5408 - val_acc: 0.8230\n",
      "Epoch 26/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3440 - acc: 0.8762\n",
      "Epoch 00026: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 12s 250us/sample - loss: 0.3443 - acc: 0.8761 - val_loss: 0.5459 - val_acc: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3311 - acc: 0.8810\n",
      "Epoch 00027: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 12s 241us/sample - loss: 0.3314 - acc: 0.8809 - val_loss: 0.5470 - val_acc: 0.8240\n",
      "Epoch 28/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8838\n",
      "Epoch 00028: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 0.3237 - acc: 0.8838 - val_loss: 0.5523 - val_acc: 0.8219\n",
      "Epoch 29/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.8829\n",
      "Epoch 00029: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 217us/sample - loss: 0.3219 - acc: 0.8829 - val_loss: 0.5544 - val_acc: 0.8199\n",
      "Epoch 30/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8877\n",
      "Epoch 00030: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 217us/sample - loss: 0.3139 - acc: 0.8878 - val_loss: 0.5612 - val_acc: 0.8199\n",
      "Epoch 31/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.8897\n",
      "Epoch 00031: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 215us/sample - loss: 0.3077 - acc: 0.8897 - val_loss: 0.5659 - val_acc: 0.8244\n",
      "Epoch 32/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.2962 - acc: 0.8934\n",
      "Epoch 00032: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2962 - acc: 0.8934 - val_loss: 0.5505 - val_acc: 0.8264\n",
      "Epoch 33/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.8944\n",
      "Epoch 00033: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2935 - acc: 0.8944 - val_loss: 0.5528 - val_acc: 0.8250\n",
      "Epoch 34/40\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8977\n",
      "Epoch 00034: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2880 - acc: 0.8978 - val_loss: 0.5534 - val_acc: 0.8259\n",
      "Epoch 35/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.8993\n",
      "Epoch 00035: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2766 - acc: 0.8992 - val_loss: 0.5642 - val_acc: 0.8208\n",
      "Epoch 36/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9003\n",
      "Epoch 00036: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 218us/sample - loss: 0.2804 - acc: 0.9003 - val_loss: 0.5587 - val_acc: 0.8246\n",
      "Epoch 37/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2713 - acc: 0.9033\n",
      "Epoch 00037: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2714 - acc: 0.9032 - val_loss: 0.5524 - val_acc: 0.8281\n",
      "Epoch 38/40\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9048\n",
      "Epoch 00038: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2617 - acc: 0.9048 - val_loss: 0.5521 - val_acc: 0.8310\n",
      "Epoch 39/40\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.9073\n",
      "Epoch 00039: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 216us/sample - loss: 0.2603 - acc: 0.9073 - val_loss: 0.5664 - val_acc: 0.8267\n",
      "Epoch 40/40\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2544 - acc: 0.9083\n",
      "Epoch 00040: val_loss did not improve from 0.54084\n",
      "50000/50000 [==============================] - 11s 217us/sample - loss: 0.2548 - acc: 0.9081 - val_loss: 0.5678 - val_acc: 0.8254\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('weights/cifar10_best_weights.hdf5', monitor = 'val_loss', \n",
    "                             mode = 'min', save_best_only = True, \n",
    "                             verbose = 1)\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data = (testX, testY), \n",
    "              batch_size = 64, epochs = 40, callbacks = callbacks, \n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
